---
  title: "diversity_global_aquatic_insect"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# plot VPA_St (Fig5)
```{r}
library(vegan)
library(ggvenn)

data=read.csv("sample effect.csv",header = T)
enm=scale(data[,14:33])
data=data.frame(data[,1:13],enm)

enm.hy=data[,c(14:18)]
enm.cl=data[,c(19:23)]
enm.ge=data[,c(24:28)]
enm.an=data[,c(29:33)]


par(mfrow=c(2,3))
#####  TDq0
vpa.TDq0=varpart(data[,2],enm.hy,enm.cl,enm.ge,enm.an)
plot(vpa.TDq0,Xnames=c("Hydrology", "Climate","Geomorphological","Anthropogenic"),
     bg = c("darkseagreen","#78bee5","#e7a40e","lightpink"))

#####  TDq1
vpa.TDq1=varpart(data[,4],enm.hy,enm.cl,enm.ge,enm.an)
plot(vpa.TDq1,Xnames=c("Hydrology", "Climate","Geomorphological","Anthropogenic"),
     bg = c("darkseagreen","#78bee5","#e7a40e","lightpink"))
#####  TDq2
vpa.TDq2=varpart(data[,6],enm.hy,enm.cl,enm.ge,enm.an)
plot(vpa.TDq2,Xnames=c("Hydrology", "Climate","Geomorphological","Anthropogenic"),
     bg = c("darkseagreen","#78bee5","#e7a40e","lightpink"))


#################### FD
#####  FDq0
vpa.FDq0=varpart(data[,8],enm.hy,enm.cl,enm.ge,enm.an)
plot(vpa.FDq0,Xnames=c("Hydrology", "Climate","Geomorphological","Anthropogenic"),
     bg = c("darkseagreen","#78bee5","#e7a40e","lightpink"))

#####  FDq1
vpa.FDq1=varpart(data[,10],enm.hy,enm.cl,enm.ge,enm.an)
plot(vpa.FDq1,Xnames=c("Hydrology", "Climate","Geomorphological","Anthropogenic"),
     bg = c("darkseagreen","#78bee5","#e7a40e","lightpink"))

#####  FDq2
vpa.FDq2=varpart(data[,12],enm.hy,enm.cl,enm.ge,enm.an)
plot(vpa.FDq2,Xnames=c("Hydrology", "Climate","Geomorphological","Anthropogenic"),
     bg = c("darkseagreen","#78bee5","#e7a40e","lightpink"))

colnames(enm.hy)
colnames(enm.cl)
colnames(enm.ge)
colnames(enm.an)

```

# plot VPA_Ob
```{r}
library(vegan)
library(ggvenn)

data=read.csv("sample effect.csv",header = T)
enm=scale(data[,14:33])
data=data.frame(data[,1:13],enm)

enm.hy=data[,c(14:18)]
enm.cl=data[,c(19:23)]
enm.ge=data[,c(24:28)]
enm.an=data[,c(29:33)]


par(mfrow=c(2,3))
#####  TDq0
vpa.TDq0=varpart(data[,3],enm.hy,enm.cl,enm.ge,enm.an)
plot(vpa.TDq0,Xnames=c("Hydrology", "Climate","Geomorphological","Anthropogenic"),
     bg = c("darkseagreen","#78bee5","#e7a40e","lightpink"))

#####  TDq1
vpa.TDq1=varpart(data[,5],enm.hy,enm.cl,enm.ge,enm.an)
plot(vpa.TDq1,Xnames=c("Hydrology", "Climate","Geomorphological","Anthropogenic"),
     bg = c("darkseagreen","#78bee5","#e7a40e","lightpink"))
#####  TDq2
vpa.TDq2=varpart(data[,7],enm.hy,enm.cl,enm.ge,enm.an)
plot(vpa.TDq2,Xnames=c("Hydrology", "Climate","Geomorphological","Anthropogenic"),
     bg = c("darkseagreen","#78bee5","#e7a40e","lightpink"))


#################### FD
#####  FDq0
vpa.FDq0=varpart(data[,9],enm.hy,enm.cl,enm.ge,enm.an)
plot(vpa.FDq0,Xnames=c("Hydrology", "Climate","Geomorphological","Anthropogenic"),
     bg = c("darkseagreen","#78bee5","#e7a40e","lightpink"))

#####  FDq1
vpa.FDq1=varpart(data[,11],enm.hy,enm.cl,enm.ge,enm.an)
plot(vpa.FDq1,Xnames=c("Hydrology", "Climate","Geomorphological","Anthropogenic"),
     bg = c("darkseagreen","#78bee5","#e7a40e","lightpink"))

#####  FDq2
vpa.FDq2=varpart(data[,13],enm.hy,enm.cl,enm.ge,enm.an)
plot(vpa.FDq2,Xnames=c("Hydrology", "Climate","Geomorphological","Anthropogenic"),
     bg = c("darkseagreen","#78bee5","#e7a40e","lightpink"))

colnames(enm.hy)
colnames(enm.cl)
colnames(enm.ge)
colnames(enm.an)

```


# Fig S18 - S21
```{r}
library(GGally)
library(corrplot)
library(ggplot2)
Bio=read.csv("Bio_all.csv",header = T)
ggpairs(Bio[,c(2:8)])+
  theme_bw()

#OLD=read.csv("OLD.csv",header = T)
#old=OLD[which(OLD$HYBAS_ID  %in% basin_ID$i),]
#NEW=read.csv("NEW.csv",header = T)
#new=NEW[which(NEW$HYBAS_ID  %in% basin_ID$i),]
#merge=merge(old,new,by="HYBAS_ID")
#write.csv(merge,file="env318.csv")

ggsave("Cor00.pdf", height = 7, width = 11)


enm=read.csv("env.csv",head=T)


cols_to_standardize <- 3:46
enm[, cols_to_standardize] <- scale(enm[, cols_to_standardize])


ggpairs(enm[,c(3:11)])+
  theme_bw()+
  theme(strip.background = element_rect(fill = "darkseagreen"))
ggsave("Cor01.pdf", height = 7, width = 11)

ggpairs(enm[,c(12:30)])+
  theme_bw()+
  theme(strip.background = element_rect(fill = "#88c4e8"))
ggsave("Cor02.pdf", height = 13, width = 13)

ggpairs(enm[,c(31:39)])+
  theme_bw()+
  theme(strip.background = element_rect(fill = "#E6E600FF"))
ggsave("Cor03.pdf", height = 7, width = 11)


ggpairs(enm[,c(40:46)])+
  theme_bw()+
  theme(strip.background = element_rect(fill = "pink"))
ggsave("Cor04.pdf", height = 7, width = 11)
```


# Latitude (Fig4)
```{r}
library(sf)
library(tidyverse)
library(tidycensus)
library(corrr)
library(tmap)
library(spdep)
library(tigris)
library(rmapshaper)
library(flextable)
library(car)
library(spatialreg)
library(stargazer)
library(spatialreg)
library(spdep)
library(gcookbook)
library(ggplot2)
library(ggthemes)

shp=st_read("Global basin.shp")
valid_shapefile <- st_make_valid(shp)
basins_boundaries <- st_geometry(valid_shapefile)
basins_centroids <- st_centroid(basins_boundaries)
valid_shapefile$average_latitude <- st_coordinates(basins_centroids)[, 2]
latitude=valid_shapefile[which(valid_shapefile$HYBAS_ID %in% data$HYBAS_ID), c(1,17)]
latitude=as.data.frame(latitude[,c(1:2)])
colnames(data)[1] <- "HYBAS_ID"
latitude_data=merge(data, latitude,  by = "HYBAS_ID")
L_data=latitude_data[,c(1:3,6,7,56)]


#TDq0

ggplot(L_data, aes(x = average_latitude, y = TDq0)) +
  geom_point(color = "#7acfff", size = 2) +
  stat_smooth(method = "loess", formula = y ~ x, span = 0.5, color = "steelblue3", fill = "skyblue") +
  labs(x = "average_latitude", y = "TDq0", title = "Scatterplot", caption = "Source: gcookbook") +
  theme_few() +
  theme(axis.text.x = element_text(size = 16), axis.text.y = element_text(size = 16))

ggsave("L_TDq0new.pdf", height = 4, width = 7)

#TDq1

ggplot(L_data, aes(x = average_latitude, y = TDq1)) +
  geom_point(color = "#7acfff", size = 2) +
  stat_smooth(method = "loess", formula = y ~ x, span = 0.5, color = "steelblue3", fill = "skyblue") +
  labs(x = "average_latitude", y = "TDq1", title = "Scatterplot", caption = "Source: gcookbook") +
  theme_few() +
  theme(axis.text.x = element_text(size = 16), axis.text.y = element_text(size = 16))

ggsave("L_TDq1new.pdf", height = 4, width = 7)

#FDq0

ggplot(L_data, aes(x = average_latitude, y = FDq0)) +
  geom_point( color = "orange", size = 2) +
  stat_smooth(method = "loess", formula = y ~ x, span = 0.5, color = "tomato1",fill="#ffbd88")+
  labs(x = "average_latitude", y = "FDq0", title = "Scatterplot", caption = "Source: gcookbook") +
  theme_few() +
  theme(axis.text.x = element_text(size = 16), axis.text.y = element_text(size = 16))

ggsave("L_FDq0new.pdf", height = 4, width = 7)

#FDq1

ggplot(L_data, aes(x = average_latitude, y = FDq1)) +
  geom_point( color = "orange", size = 2) +
  stat_smooth(method = "loess", formula = y ~ x, span = 0.5, color = "tomato1",fill="#ffbd88")+
  labs(x = "average_latitude", y = "FDq1", title = "Scatterplot", caption = "Source: gcookbook") +
  theme_few() +
  theme(axis.text.x = element_text(size = 16), axis.text.y = element_text(size = 16))

ggsave("L_FDq1new.pdf", height = 4, width = 7)
```


#RFM prediction (Fig 4E and F)
```{r}
# 加载必要的包
library(randomForest)
library(Metrics)

# 读取数据
text_df <- read.csv("predication.csv")
new_df <- read.csv("test.csv")

# 查看数据结构
str(text_df)
str(new_df)
# 定义目标变量和特征变量
target_columns <- c("TDq0", "TDq1","TDq2" ,"FDq0", "FDq1", "FDq2")
feature_columns <- setdiff(names(new_df), c(target_columns, "Obs_TDq0", "Obs_TDq1", "Obs_TDq2","Obs_FDq0","Obs_FDq1", "Obs_FDq2","Sam_eff", "HYBAS_ID"))

# 初始化结果列表
results <- list()

# 创建一个新的数据框来存储预测结果
predictions_df <- text_df

# 建立模型并进行预测
for (target in target_columns) {
  # 拆分数据为特征和目标变量
  X <- new_df[, feature_columns]
  y <- new_df[, target]
  
  # 初始化和训练模型
  model <- randomForest(X, y, random_state=42)
  
  # 进行预测
  predictions <- predict(model, X)
  
  # 评估模型
  rmse_value <- rmse(y, predictions)
  r2_value <- cor(y, predictions)^2
  
  # 保存模型表现
  results[[target]] <- c(R2 = r2_value, RMSE = rmse_value)
  
  # 对新数据进行预测
  predictions_df[, target] <- predict(model, text_df[, feature_columns])
}

results_df <- do.call(rbind, results)
colnames(results_df) <- c("R2", "RMSE")


print(results_df)
#write.csv(predictions_df,file = "predictions_df.csv")
```


# Regression plots
```{r}
# Load necessary packages
library(randomForest)
library(Metrics)
library(ggplot2)
library(caret)
library(pdp)
library(gridExtra)

# Read data
text_df <- read.csv("predication.csv")
new_df <- read.csv("test.csv")

# View data structure
str(text_df)
str(new_df)

# Define target and feature columns
target_columns <- c("TDq0", "TDq1", "TDq2", "FDq0", "FDq1", "FDq2")
feature_columns <- setdiff(names(new_df), c(target_columns, "Obs_TDq0", "Obs_TDq1", "Obs_TDq2","Obs_FDq0","Obs_FDq1", "Obs_FDq2","Sam_eff", "HYBAS_ID"))

# Initialize results list
results <- list()

# Create a new dataframe to store predictions
predictions_df <- text_df

# Data partitioning
set.seed(42)
trainIndex <- createDataPartition(new_df$TDq0, p = .8, list = FALSE)
trainData <- new_df[trainIndex, ]
testData <- new_df[-trainIndex, ]

# Train, test, and validation split
validationIndex <- createDataPartition(testData$TDq0, p = .5, list = FALSE)
validationData <- testData[validationIndex, ]
testData <- testData[-validationIndex, ]

# Function to generate combined regression plot
combined_regression_plot <- function(trainData, testData, validationData, target, feature_columns) {
  model <- randomForest(trainData[, feature_columns], trainData[, target], random_state=42)
  
  train_pred <- predict(model, trainData[, feature_columns])
  test_pred <- predict(model, testData[, feature_columns])
  validation_pred <- predict(model, validationData[, feature_columns])
  
  data <- data.frame(
    Observed = c(trainData[, target], testData[, target], validationData[, target]),
    Predicted = c(train_pred, test_pred, validation_pred),
    Set = rep(c("Train", "Test", "Validate"), c(nrow(trainData), nrow(testData), nrow(validationData)))
  )
  
  rmse_train <- rmse(trainData[, target], train_pred)
  r2_train <- cor(trainData[, target], train_pred)^2
  rmse_test <- rmse(testData[, target], test_pred)
  r2_test <- cor(testData[, target], test_pred)^2
  rmse_validation <- rmse(validationData[, target], validation_pred)
  r2_validation <- cor(validationData[, target], validation_pred)^2
  
  ggplot(data, aes(x = Observed, y = Predicted, color = Set)) +
    geom_point() +
    geom_smooth(method = "lm", se = TRUE, fullrange = TRUE) +
    geom_abline(slope = 1, intercept = 0, color = "gray") +
    ggtitle(paste("Predicted vs Observed", target, "(Random Forest)")) +
    theme_minimal() +
    annotate("text", x = Inf, y = Inf, label = paste("RMSE (Train):", round(rmse_train, 2), "\nR² (Train):", round(r2_train, 2),
                                                     "\nRMSE (Test):", round(rmse_test, 2), "\nR² (Test):", round(r2_test, 2),
                                                     "\nRMSE (Validate):", round(rmse_validation, 2), "\nR² (Validate):", round(r2_validation, 2)),
             hjust = 1.1, vjust = 2, size = 3.5, color = "black")
}

# Generate plots for each target and save them in a list
plot_list <- list()
for (target in target_columns) {
  plot_list[[target]] <- combined_regression_plot(trainData, testData, validationData, target, feature_columns)
}

# Arrange all plots in a single output using gridExtra
pdf("combined_plots.pdf", height = 11, width = 8.5)
grid.arrange(grobs = plot_list, ncol = 2)
dev.off()

```


# Fig S10 - S13
# PDP TD
```{r}
# Load necessary packages
library(randomForest)
library(Metrics)
library(ggplot2)
library(caret)
library(pdp)
library(gridExtra)

# Read data
text_df <- read.csv("predication.csv")
new_df <- read.csv("test.csv")

# View data structure
str(text_df)
str(new_df)

# Define target and feature columns
target_columns <- c("TDq0", "TDq1", "TDq2")
feature_columns <- setdiff(names(new_df), c(target_columns, "Obs_TDq0", "Obs_TDq1", "Obs_TDq2","Obs_FDq0","Obs_FDq1", "Obs_FDq2","Sam_eff", "HYBAS_ID","FDq0", "FDq1", "FDq2"))

# Initialize results list
results <- list()

# Create a new dataframe to store predictions
predictions_df <- text_df

# Data partitioning
set.seed(42)
trainIndex <- createDataPartition(new_df$TDq0, p = .8, list = FALSE)
trainData <- new_df[trainIndex, ]
testData <- new_df[-trainIndex, ]

# Train, test, and validation split
validationIndex <- createDataPartition(testData$TDq0, p = .5, list = FALSE)
validationData <- testData[validationIndex, ]
testData <- testData[-validationIndex, ]

# Function to generate combined regression plot
combined_regression_plot <- function(trainData, testData, validationData, target, feature_columns) {
  model <- randomForest(trainData[, feature_columns], trainData[, target], random_state=42)
  
  train_pred <- predict(model, trainData[, feature_columns])
  test_pred <- predict(model, testData[, feature_columns])
  validation_pred <- predict(model, validationData[, feature_columns])
  
  data <- data.frame(
    Observed = c(trainData[, target], testData[, target], validationData[, target]),
    Predicted = c(train_pred, test_pred, validation_pred),
    Set = rep(c("Train", "Test", "Validate"), c(nrow(trainData), nrow(testData), nrow(validationData)))
  )
  
  rmse_train <- rmse(trainData[, target], train_pred)
  r2_train <- cor(trainData[, target], train_pred)^2
  rmse_test <- rmse(testData[, target], test_pred)
  r2_test <- cor(testData[, target], test_pred)^2
  rmse_validation <- rmse(validationData[, target], validation_pred)
  r2_validation <- cor(validationData[, target], validation_pred)^2
  
  ggplot(data, aes(x = Observed, y = Predicted, color = Set)) +
    geom_point() +
    geom_smooth(method = "lm", se = TRUE, fullrange = TRUE) +
    geom_abline(slope = 1, intercept = 0, color = "gray") +
    ggtitle(paste("Predicted vs Observed", target, "(Random Forest)")) +
    theme_minimal() +
    annotate("text", x = Inf, y = Inf, label = paste("RMSE (Train):", round(rmse_train, 2), "\nR² (Train):", round(r2_train, 2),
                                                     "\nRMSE (Test):", round(rmse_test, 2), "\nR² (Test):", round(r2_test, 2),
                                                     "\nRMSE (Validate):", round(rmse_validation, 2), "\nR² (Validate):", round(r2_validation, 2)),
             hjust = 1.1, vjust = 2, size = 3.5, color = "black")
}

# Function to generate partial dependence plot for multiple targets
generate_partial_dependence_plot <- function(models, data, targets, feature) {
  pdp_data <- do.call(rbind, lapply(seq_along(targets), function(i) {
    pdp_obj <- partial(models[[i]], pred.var = feature, train = data)
    pdp_obj$target <- targets[i]
    pdp_obj
  }))
  
  ggplot(pdp_data, aes(x = !!sym(feature), y = yhat, color = target)) +
    geom_line() +
    ggtitle(paste("Partial Dependence on", feature)) +
    theme_classic() +
    theme(panel.border = element_rect(colour = "black", fill = NA, size = 1))
}

# Train the models for each target and generate PDP plots
models <- list()
for (target in target_columns) {
  models[[target]] <- randomForest(trainData[, feature_columns], trainData[, target], random_state=42)
}

# Generate combined PDP plots for all features
pdp_plot_list <- list()
for (feature in feature_columns) {
  pdp_plot_list[[feature]] <- generate_partial_dependence_plot(models, trainData, target_columns, feature)
}

# Save PDP plots to a PDF
pdf("pdp_TD.pdf", height = 15, width = 20)
grid.arrange(grobs = pdp_plot_list, ncol = 5)
dev.off()

```

# PDP FD
```{r}
# Load necessary packages
library(randomForest)
library(Metrics)
library(ggplot2)
library(caret)
library(pdp)
library(gridExtra)

# Read data
text_df <- read.csv("predication.csv")
new_df <- read.csv("test.csv")

# View data structure
str(text_df)
str(new_df)

# Define target and feature columns
target_columns <- c("FDq0", "FDq1", "FDq2")
feature_columns <- setdiff(names(new_df), c(target_columns, "Obs_TDq0", "Obs_TDq1", "Obs_TDq2","Obs_FDq0","Obs_FDq1", "Obs_FDq2","Sam_eff", "HYBAS_ID","TDq0", "TDq1", "TDq2"))

# Initialize results list
results <- list()

# Create a new dataframe to store predictions
predictions_df <- text_df

# Data partitioning
set.seed(42)
trainIndex <- createDataPartition(new_df$TDq0, p = .8, list = FALSE)
trainData <- new_df[trainIndex, ]
testData <- new_df[-trainIndex, ]

# Train, test, and validation split
validationIndex <- createDataPartition(testData$TDq0, p = .5, list = FALSE)
validationData <- testData[validationIndex, ]
testData <- testData[-validationIndex, ]

# Function to generate combined regression plot
combined_regression_plot <- function(trainData, testData, validationData, target, feature_columns) {
  model <- randomForest(trainData[, feature_columns], trainData[, target], random_state=42)
  
  train_pred <- predict(model, trainData[, feature_columns])
  test_pred <- predict(model, testData[, feature_columns])
  validation_pred <- predict(model, validationData[, feature_columns])
  
  data <- data.frame(
    Observed = c(trainData[, target], testData[, target], validationData[, target]),
    Predicted = c(train_pred, test_pred, validation_pred),
    Set = rep(c("Train", "Test", "Validate"), c(nrow(trainData), nrow(testData), nrow(validationData)))
  )
  
  rmse_train <- rmse(trainData[, target], train_pred)
  r2_train <- cor(trainData[, target], train_pred)^2
  rmse_test <- rmse(testData[, target], test_pred)
  r2_test <- cor(testData[, target], test_pred)^2
  rmse_validation <- rmse(validationData[, target], validation_pred)
  r2_validation <- cor(validationData[, target], validation_pred)^2
  
  ggplot(data, aes(x = Observed, y = Predicted, color = Set)) +
    geom_point() +
    geom_smooth(method = "lm", se = TRUE, fullrange = TRUE) +
    geom_abline(slope = 1, intercept = 0, color = "gray") +
    ggtitle(paste("Predicted vs Observed", target, "(Random Forest)")) +
    theme_minimal() +
    annotate("text", x = Inf, y = Inf, label = paste("RMSE (Train):", round(rmse_train, 2), "\nR² (Train):", round(r2_train, 2),
                                                     "\nRMSE (Test):", round(rmse_test, 2), "\nR² (Test):", round(r2_test, 2),
                                                     "\nRMSE (Validate):", round(rmse_validation, 2), "\nR² (Validate):", round(r2_validation, 2)),
             hjust = 1.1, vjust = 2, size = 3.5, color = "black")
}

# Function to generate partial dependence plot for multiple targets
generate_partial_dependence_plot <- function(models, data, targets, feature) {
  pdp_data <- do.call(rbind, lapply(seq_along(targets), function(i) {
    pdp_obj <- partial(models[[i]], pred.var = feature, train = data)
    pdp_obj$target <- targets[i]
    pdp_obj
  }))
  
  ggplot(pdp_data, aes(x = !!sym(feature), y = yhat, color = target)) +
    geom_line() +
    ggtitle(paste("Partial Dependence on", feature)) +
    theme_classic() +
    theme(panel.border = element_rect(colour = "black", fill = NA, size = 1))
}

# Train the models for each target and generate PDP plots
models <- list()
for (target in target_columns) {
  models[[target]] <- randomForest(trainData[, feature_columns], trainData[, target], random_state=42)
}

# Generate combined PDP plots for all features
pdp_plot_list <- list()
for (feature in feature_columns) {
  pdp_plot_list[[feature]] <- generate_partial_dependence_plot(models, trainData, target_columns, feature)
}

# Save PDP plots to a PDF
pdf("pdp_FD.pdf", height = 15, width = 20)
grid.arrange(grobs = pdp_plot_list, ncol = 5)
dev.off()

```


# PDP obs_TD
```{r}
# Load necessary packages
library(randomForest)
library(Metrics)
library(ggplot2)
library(caret)
library(pdp)
library(gridExtra)

# Read data
text_df <- read.csv("predication.csv")
new_df <- read.csv("test.csv")

# View data structure
str(text_df)
str(new_df)

# Define target and feature columns
target_columns <- c("Obs_TDq0", "Obs_TDq1", "Obs_TDq2")
feature_columns <- setdiff(names(new_df), c(target_columns, "TDq0", "TDq1", "TDq2","Obs_FDq0","Obs_FDq1", "Obs_FDq2","Sam_eff", "HYBAS_ID","FDq0", "FDq1", "FDq2"))

# Initialize results list
results <- list()

# Create a new dataframe to store predictions
predictions_df <- text_df

# Data partitioning
set.seed(42)
trainIndex <- createDataPartition(new_df$TDq0, p = .8, list = FALSE)
trainData <- new_df[trainIndex, ]
testData <- new_df[-trainIndex, ]

# Train, test, and validation split
validationIndex <- createDataPartition(testData$TDq0, p = .5, list = FALSE)
validationData <- testData[validationIndex, ]
testData <- testData[-validationIndex, ]

# Function to generate combined regression plot
combined_regression_plot <- function(trainData, testData, validationData, target, feature_columns) {
  model <- randomForest(trainData[, feature_columns], trainData[, target], random_state=42)
  
  train_pred <- predict(model, trainData[, feature_columns])
  test_pred <- predict(model, testData[, feature_columns])
  validation_pred <- predict(model, validationData[, feature_columns])
  
  data <- data.frame(
    Observed = c(trainData[, target], testData[, target], validationData[, target]),
    Predicted = c(train_pred, test_pred, validation_pred),
    Set = rep(c("Train", "Test", "Validate"), c(nrow(trainData), nrow(testData), nrow(validationData)))
  )
  
  rmse_train <- rmse(trainData[, target], train_pred)
  r2_train <- cor(trainData[, target], train_pred)^2
  rmse_test <- rmse(testData[, target], test_pred)
  r2_test <- cor(testData[, target], test_pred)^2
  rmse_validation <- rmse(validationData[, target], validation_pred)
  r2_validation <- cor(validationData[, target], validation_pred)^2
  
  ggplot(data, aes(x = Observed, y = Predicted, color = Set)) +
    geom_point() +
    geom_smooth(method = "lm", se = TRUE, fullrange = TRUE) +
    geom_abline(slope = 1, intercept = 0, color = "gray") +
    ggtitle(paste("Predicted vs Observed", target, "(Random Forest)")) +
    theme_minimal() +
    annotate("text", x = Inf, y = Inf, label = paste("RMSE (Train):", round(rmse_train, 2), "\nR² (Train):", round(r2_train, 2),
                                                     "\nRMSE (Test):", round(rmse_test, 2), "\nR² (Test):", round(r2_test, 2),
                                                     "\nRMSE (Validate):", round(rmse_validation, 2), "\nR² (Validate):", round(r2_validation, 2)),
             hjust = 1.1, vjust = 2, size = 3.5, color = "black")
}

# Function to generate partial dependence plot for multiple targets
generate_partial_dependence_plot <- function(models, data, targets, feature) {
  pdp_data <- do.call(rbind, lapply(seq_along(targets), function(i) {
    pdp_obj <- partial(models[[i]], pred.var = feature, train = data)
    pdp_obj$target <- targets[i]
    pdp_obj
  }))
  
  ggplot(pdp_data, aes(x = !!sym(feature), y = yhat, color = target)) +
    geom_line() +
    ggtitle(paste("Partial Dependence on", feature)) +
    theme_classic() +
    theme(panel.border = element_rect(colour = "black", fill = NA, size = 1))
}

# Train the models for each target and generate PDP plots
models <- list()
for (target in target_columns) {
  models[[target]] <- randomForest(trainData[, feature_columns], trainData[, target], random_state=42)
}

# Generate combined PDP plots for all features
pdp_plot_list <- list()
for (feature in feature_columns) {
  pdp_plot_list[[feature]] <- generate_partial_dependence_plot(models, trainData, target_columns, feature)
}

# Save PDP plots to a PDF
pdf("pdp_TDob.pdf", height = 15, width = 23)
grid.arrange(grobs = pdp_plot_list, ncol = 5)
dev.off()

```

# PDP obs_FD
```{r}
# Load necessary packages
library(randomForest)
library(Metrics)
library(ggplot2)
library(caret)
library(pdp)
library(gridExtra)

# Read data
text_df <- read.csv("predication.csv")
new_df <- read.csv("test.csv")

# View data structure
str(text_df)
str(new_df)

# Define target and feature columns
target_columns <- c("Obs_FDq0", "Obs_FDq1", "Obs_FDq2")
feature_columns <- setdiff(names(new_df), c(target_columns, "TDq0", "TDq1", "TDq2","Obs_TDq0","Obs_TDq1", "Obs_TDq2","Sam_eff", "HYBAS_ID","FDq0", "FDq1", "FDq2"))

# Initialize results list
results <- list()

# Create a new dataframe to store predictions
predictions_df <- text_df

# Data partitioning
set.seed(42)
trainIndex <- createDataPartition(new_df$TDq0, p = .8, list = FALSE)
trainData <- new_df[trainIndex, ]
testData <- new_df[-trainIndex, ]

# Train, test, and validation split
validationIndex <- createDataPartition(testData$TDq0, p = .5, list = FALSE)
validationData <- testData[validationIndex, ]
testData <- testData[-validationIndex, ]

# Function to generate combined regression plot
combined_regression_plot <- function(trainData, testData, validationData, target, feature_columns) {
  model <- randomForest(trainData[, feature_columns], trainData[, target], random_state=42)
  
  train_pred <- predict(model, trainData[, feature_columns])
  test_pred <- predict(model, testData[, feature_columns])
  validation_pred <- predict(model, validationData[, feature_columns])
  
  data <- data.frame(
    Observed = c(trainData[, target], testData[, target], validationData[, target]),
    Predicted = c(train_pred, test_pred, validation_pred),
    Set = rep(c("Train", "Test", "Validate"), c(nrow(trainData), nrow(testData), nrow(validationData)))
  )
  
  rmse_train <- rmse(trainData[, target], train_pred)
  r2_train <- cor(trainData[, target], train_pred)^2
  rmse_test <- rmse(testData[, target], test_pred)
  r2_test <- cor(testData[, target], test_pred)^2
  rmse_validation <- rmse(validationData[, target], validation_pred)
  r2_validation <- cor(validationData[, target], validation_pred)^2
  
  ggplot(data, aes(x = Observed, y = Predicted, color = Set)) +
    geom_point() +
    geom_smooth(method = "lm", se = TRUE, fullrange = TRUE) +
    geom_abline(slope = 1, intercept = 0, color = "gray") +
    ggtitle(paste("Predicted vs Observed", target, "(Random Forest)")) +
    theme_minimal() +
    annotate("text", x = Inf, y = Inf, label = paste("RMSE (Train):", round(rmse_train, 2), "\nR² (Train):", round(r2_train, 2),
                                                     "\nRMSE (Test):", round(rmse_test, 2), "\nR² (Test):", round(r2_test, 2),
                                                     "\nRMSE (Validate):", round(rmse_validation, 2), "\nR² (Validate):", round(r2_validation, 2)),
             hjust = 1.1, vjust = 2, size = 3.5, color = "black")
}

# Function to generate partial dependence plot for multiple targets
generate_partial_dependence_plot <- function(models, data, targets, feature) {
  pdp_data <- do.call(rbind, lapply(seq_along(targets), function(i) {
    pdp_obj <- partial(models[[i]], pred.var = feature, train = data)
    pdp_obj$target <- targets[i]
    pdp_obj
  }))
  
  ggplot(pdp_data, aes(x = !!sym(feature), y = yhat, color = target)) +
    geom_line() +
    ggtitle(paste("Partial Dependence on", feature)) +
    theme_classic() +
    theme(panel.border = element_rect(colour = "black", fill = NA, size = 1))
}

# Train the models for each target and generate PDP plots
models <- list()
for (target in target_columns) {
  models[[target]] <- randomForest(trainData[, feature_columns], trainData[, target], random_state=42)
}

# Generate combined PDP plots for all features
pdp_plot_list <- list()
for (feature in feature_columns) {
  pdp_plot_list[[feature]] <- generate_partial_dependence_plot(models, trainData, target_columns, feature)
}

# Save PDP plots to a PDF
pdf("pdp_FDob.pdf", height = 15, width = 23)
grid.arrange(grobs = pdp_plot_list, ncol = 5)
dev.off()

```

